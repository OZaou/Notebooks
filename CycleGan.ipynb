{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "78e982c3-d38b-4faa-a8fb-ce9576061f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import make_grid, save_image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a4d93b-360e-4f95-a2a9-249421210a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b83ee0-a493-4a1d-bfcc-447e1e0b1870",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "!pip install gdown\n",
    "data_root = './data/celeba'\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.CenterCrop(128),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # Normalize to [-1, 1]\n",
    "])\n",
    "\n",
    "celeba_train = datasets.CelebA(root=data_root, split='train', target_type='attr', download=True, transform=transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc671e1b-53ef-4ab5-9ffb-1b564c17b5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of attributes in order\n",
    "celeba_attributes = celeba_train.attr_names\n",
    "print(\"List of attributes in CelebA:\")\n",
    "for idx, attr in enumerate(celeba_attributes):\n",
    "    print(f\"{idx}: {attr}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84cd806e-03c8-4eef-bce4-7c137be7746c",
   "metadata": {},
   "outputs": [],
   "source": [
    "smiling_attr = celeba_train.attr[:, 31]\n",
    "unique_values = np.unique(smiling_attr)\n",
    "print(f\"Unique values for 'Smiling' attribute: {unique_values}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "dec6e5c4-9eb5-48b6-bba2-bdf9326f762d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CelebADataset(Dataset):\n",
    "    def __init__(self, celeba_dataset, domain_attribute=31, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            celeba_dataset (Dataset): The CelebA dataset.\n",
    "            domain_attribute (int): Index of the attribute to define domains.\n",
    "                                    31 corresponds to 'Smiling'.\n",
    "            transform (callable, optional): Optional transform to be applied on a sample.\n",
    "        \"\"\"\n",
    "        self.celeba = celeba_dataset\n",
    "        self.transform = transform\n",
    "        self.attr = self.celeba.attr\n",
    "        self.domain_attribute = domain_attribute\n",
    "        \n",
    "        # Split into two domains based on the attribute encoding\n",
    "        self.domain_A_indices = np.where(self.attr[:, self.domain_attribute] == 1)[0]  # Smiling\n",
    "        if -1 in self.attr[:, self.domain_attribute]:\n",
    "            self.domain_B_indices = np.where(self.attr[:, self.domain_attribute] == -1)[0]  # Not Smiling\n",
    "            label_neg = -1\n",
    "        elif 0 in self.attr[:, self.domain_attribute]:\n",
    "            self.domain_B_indices = np.where(self.attr[:, self.domain_attribute] == 0)[0]  # Not Smiling\n",
    "            label_neg = 0\n",
    "        else:\n",
    "            raise ValueError(f\"Unexpected labels for 'Smiling' attribute: {np.unique(self.attr[:, self.domain_attribute])}\")\n",
    "        \n",
    "        # Safety check\n",
    "        if len(self.domain_A_indices) == 0:\n",
    "            raise ValueError(f\"No samples found for Domain A (Smiling) with attribute index {self.domain_attribute}.\")\n",
    "        if len(self.domain_B_indices) == 0:\n",
    "            raise ValueError(f\"No samples found for Domain B (Not Smiling) with attribute index {self.domain_attribute}.\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return max(len(self.domain_A_indices), len(self.domain_B_indices))\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        idx_A = idx % len(self.domain_A_indices)\n",
    "        idx_B = idx % len(self.domain_B_indices)\n",
    "        \n",
    "        img_A, _ = self.celeba[self.domain_A_indices[idx_A]]\n",
    "        img_B, _ = self.celeba[self.domain_B_indices[idx_B]]\n",
    "        \n",
    "        return {'A': img_A, 'B': img_B}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c0950e-bd0c-48e2-b120-0298f084febf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the 'Smiling' attribute\n",
    "smiling_attr = celeba_train.attr[:, 31]\n",
    "\n",
    "# Check unique values\n",
    "unique_values = np.unique(smiling_attr)\n",
    "print(f\"Unique values for 'Smiling' attribute: {unique_values}\")\n",
    "\n",
    "# Correct attribute index for \"Smiling\"\n",
    "smiling_index = celeba_attributes.index('Smiling')  # Should be 31\n",
    "\n",
    "# Initialize the custom dataset with the correct attribute index\n",
    "celeba_custom = CelebADataset(celeba_train, domain_attribute=smiling_index, transform=transform)\n",
    "\n",
    "# Create DataLoader\n",
    "batch_size = 32\n",
    "dataloader = DataLoader(celeba_custom, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "\n",
    "# Verify the dataset\n",
    "print(f\"Number of samples in Domain A (Smiling): {len(celeba_custom.domain_A_indices)}\")\n",
    "print(f\"Number of samples in Domain B (Not Smiling): {len(celeba_custom.domain_B_indices)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "078b00a8-c681-4967-b58e-2c05e641ad41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_samples(data_loader, num_samples=4):\n",
    "    data = next(iter(data_loader))\n",
    "    imgs_A = data['A'][:num_samples]\n",
    "    imgs_B = data['B'][:num_samples]\n",
    "    \n",
    "    grid_A = make_grid(imgs_A, nrow=num_samples, normalize=True)\n",
    "    grid_B = make_grid(imgs_B, nrow=num_samples, normalize=True)\n",
    "    \n",
    "    fig, axs = plt.subplots(1, 2, figsize=(12,6))\n",
    "    axs[0].imshow(np.transpose(grid_A.numpy(), (1,2,0)))\n",
    "    axs[0].set_title(\"Domain A: Smiling\")\n",
    "    axs[0].axis('off')\n",
    "    \n",
    "    axs[1].imshow(np.transpose(grid_B.numpy(), (1,2,0)))\n",
    "    axs[1].set_title(\"Domain B: Not Smiling\")\n",
    "    axs[1].axis('off')\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "show_samples(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d1919d45-700f-4bdd-aa3d-52a67218faae",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, features):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.block = nn.Sequential(\n",
    "            nn.ReflectionPad2d(1),\n",
    "            nn.Conv2d(features, features, kernel_size=3, stride=1, padding=0),\n",
    "            nn.InstanceNorm2d(features),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.ReflectionPad2d(1),\n",
    "            nn.Conv2d(features, features, kernel_size=3, stride=1, padding=0),\n",
    "            nn.InstanceNorm2d(features)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return x + self.block(x)\n",
    "\n",
    "class ResNetGenerator(nn.Module):\n",
    "    def __init__(self, input_nc, output_nc, num_residuals=9):\n",
    "        super(ResNetGenerator, self).__init__()\n",
    "        # Initial convolution block\n",
    "        model = [\n",
    "            nn.ReflectionPad2d(3),\n",
    "            nn.Conv2d(input_nc, 64, kernel_size=7, padding=0),\n",
    "            nn.InstanceNorm2d(64),\n",
    "            nn.ReLU(inplace=True)\n",
    "        ]\n",
    "        \n",
    "        # Downsampling\n",
    "        in_features = 64\n",
    "        out_features = in_features * 2\n",
    "        for _ in range(2):\n",
    "            model += [\n",
    "                nn.Conv2d(in_features, out_features, kernel_size=3, stride=2, padding=1),\n",
    "                nn.InstanceNorm2d(out_features),\n",
    "                nn.ReLU(inplace=True)\n",
    "            ]\n",
    "            in_features = out_features\n",
    "            out_features = in_features * 2\n",
    "        \n",
    "        # Residual blocks\n",
    "        for _ in range(num_residuals):\n",
    "            model += [ResidualBlock(in_features)]\n",
    "        \n",
    "        # Upsampling\n",
    "        out_features = in_features // 2\n",
    "        for _ in range(2):\n",
    "            model += [\n",
    "                nn.ConvTranspose2d(in_features, out_features, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "                nn.InstanceNorm2d(out_features),\n",
    "                nn.ReLU(inplace=True)\n",
    "            ]\n",
    "            in_features = out_features\n",
    "            out_features = in_features // 2\n",
    "        \n",
    "        # Output layer\n",
    "        model += [\n",
    "            nn.ReflectionPad2d(3),\n",
    "            nn.Conv2d(in_features, output_nc, kernel_size=7, padding=0),\n",
    "            nn.Tanh()\n",
    "        ]\n",
    "        \n",
    "        self.model = nn.Sequential(*model)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0868f7e5-07dc-47f9-b828-bc305374c36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PatchGANDiscriminator(nn.Module):\n",
    "    def __init__(self, input_nc):\n",
    "        super(PatchGANDiscriminator, self).__init__()\n",
    "        # A sequence of convolutional layers\n",
    "        model = [\n",
    "            nn.Conv2d(input_nc, 64, kernel_size=4, stride=2, padding=1),\n",
    "            nn.LeakyReLU(0.2, inplace=True)\n",
    "        ]\n",
    "        \n",
    "        model += [\n",
    "            nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1),\n",
    "            nn.InstanceNorm2d(128),\n",
    "            nn.LeakyReLU(0.2, inplace=True)\n",
    "        ]\n",
    "        \n",
    "        model += [\n",
    "            nn.Conv2d(128, 256, kernel_size=4, stride=2, padding=1),\n",
    "            nn.InstanceNorm2d(256),\n",
    "            nn.LeakyReLU(0.2, inplace=True)\n",
    "        ]\n",
    "        \n",
    "        model += [\n",
    "            nn.Conv2d(256, 512, kernel_size=4, stride=1, padding=1),\n",
    "            nn.InstanceNorm2d(512),\n",
    "            nn.LeakyReLU(0.2, inplace=True)\n",
    "        ]\n",
    "        \n",
    "        # Output layer\n",
    "        model += [nn.Conv2d(512, 1, kernel_size=4, stride=1, padding=1)]\n",
    "        \n",
    "        self.model = nn.Sequential(*model)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c7aeac-5be8-4202-b226-cc73e4a21183",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define input and output channels\n",
    "input_nc = 3  # RGB images\n",
    "output_nc = 3\n",
    "\n",
    "# Initialize generators and discriminators\n",
    "netG_A2B = ResNetGenerator(input_nc, output_nc).to(device)  # Generator A -> B\n",
    "netG_B2A = ResNetGenerator(output_nc, input_nc).to(device)  # Generator B -> A\n",
    "\n",
    "netD_A = PatchGANDiscriminator(input_nc).to(device)  # Discriminator for domain A\n",
    "netD_B = PatchGANDiscriminator(output_nc).to(device)  # Discriminator for domain B\n",
    "\n",
    "# Print model summaries\n",
    "print(netG_A2B)\n",
    "print(netD_A)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97365ffe-da0a-49cf-8ee0-008c41715d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init_normal(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if hasattr(m, 'weight') and m.weight is not None:\n",
    "        if classname.find('Conv') != -1:\n",
    "            nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "        elif classname.find('BatchNorm2d') != -1 or classname.find('InstanceNorm2d') != -1:\n",
    "            nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "            if hasattr(m, 'bias') and m.bias is not None:\n",
    "                nn.init.constant_(m.bias.data, 0.0)\n",
    "\n",
    "# Apply the updated initialization\n",
    "netG_A2B.apply(weights_init_normal)\n",
    "netG_B2A.apply(weights_init_normal)\n",
    "netD_A.apply(weights_init_normal)\n",
    "netD_B.apply(weights_init_normal)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "81ebe99c-ebed-4f21-a8aa-e612344b820d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss functions\n",
    "criterion_GAN = nn.MSELoss().to(device)       # Least Squares GAN\n",
    "criterion_cycle = nn.L1Loss().to(device)      # Cycle Consistency Loss\n",
    "criterion_identity = nn.L1Loss().to(device)   # Identity Loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "cccd96e1-a428-40df-b640-26b2e32e7c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define learning rates and other hyperparameters\n",
    "lr = 0.0002\n",
    "beta1 = 0.5\n",
    "beta2 = 0.999\n",
    "num_epochs = 200\n",
    "lambda_cycle = 10.0\n",
    "lambda_identity = 5.0\n",
    "\n",
    "# Define optimizers\n",
    "optimizer_G = optim.Adam(\n",
    "    list(netG_A2B.parameters()) + list(netG_B2A.parameters()), \n",
    "    lr=lr, betas=(beta1, beta2)\n",
    ")\n",
    "\n",
    "optimizer_D_A = optim.Adam(netD_A.parameters(), lr=lr, betas=(beta1, beta2))\n",
    "optimizer_D_B = optim.Adam(netD_B.parameters(), lr=lr, betas=(beta1, beta2))\n",
    "\n",
    "# Define learning rate schedulers\n",
    "def lambda_rule(epoch):\n",
    "    lr_l = 1.0 - max(0, epoch - 100) / float(100 + 1)\n",
    "    return lr_l\n",
    "\n",
    "scheduler_G = optim.lr_scheduler.LambdaLR(optimizer_G, lr_lambda=lambda_rule)\n",
    "scheduler_D_A = optim.lr_scheduler.LambdaLR(optimizer_D_A, lr_lambda=lambda_rule)\n",
    "scheduler_D_B = optim.lr_scheduler.LambdaLR(optimizer_D_B, lr_lambda=lambda_rule)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "51297210-4b5c-4d2a-bde6-8d17add1b00f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "\n",
    "class ReplayBuffer:\n",
    "    def __init__(self, max_size=50):\n",
    "        assert max_size > 0,\n",
    "        self.max_size = max_size\n",
    "        self.data = deque(maxlen=max_size)\n",
    "    \n",
    "    def push_and_pop(self, data):\n",
    "        to_return = []\n",
    "        for element in data:\n",
    "            element = torch.unsqueeze(element, 0)\n",
    "            if len(self.data) < self.max_size:\n",
    "                self.data.append(element)\n",
    "                to_return.append(element)\n",
    "            else:\n",
    "                if torch.rand(1).item() > 0.5:\n",
    "                    idx = np.random.randint(0, self.max_size)\n",
    "                    tmp = self.data[idx].clone()\n",
    "                    self.data[idx] = element\n",
    "                    to_return.append(tmp)\n",
    "                else:\n",
    "                    to_return.append(element)\n",
    "        return torch.cat(to_return)\n",
    "\n",
    "# Initialize buffers\n",
    "buffer_A = ReplayBuffer()\n",
    "buffer_B = ReplayBuffer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "17ccfbb6-2529-46d6-a11d-c217df284746",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_sample_images(epoch, generator, data_loader, device, output_dir='output'):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    data = next(iter(data_loader))\n",
    "    real_A = data['A'].to(device)\n",
    "    real_B = data['B'].to(device)\n",
    "    \n",
    "    # Generate fake images\n",
    "    fake_B = generator['A2B'](real_A)\n",
    "    fake_A = generator['B2A'](real_B)\n",
    "    \n",
    "    # Reconstruct images\n",
    "    rec_A = generator['B2A'](fake_B)\n",
    "    rec_B = generator['A2B'](fake_A)\n",
    "    \n",
    "    # Create a grid of images\n",
    "    img_sample = torch.cat((real_A.data, fake_B.data, rec_A.data, real_B.data, fake_A.data, rec_B.data), 0)\n",
    "    img_grid = make_grid(img_sample, nrow=real_A.size(0), normalize=True)\n",
    "    \n",
    "    # Save the image\n",
    "    save_image(img_grid, os.path.join(output_dir, f'epoch_{epoch+1}.png'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "db93addf-7050-436b-97b9-ae72ca2fea2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = {'A2B': netG_A2B, 'B2A': netG_B2A}\n",
    "discriminator = {'A': netD_A, 'B': netD_B}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "943f188c-47e1-4ba5-a336-c1985006847d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize lists to store loss values\n",
    "G_losses = []\n",
    "D_A_losses = []\n",
    "D_B_losses = []\n",
    "cycle_losses = []\n",
    "identity_losses = []\n",
    "\n",
    "# Number of total batches\n",
    "total_steps = len(dataloader)\n",
    "\n",
    "print(\"Starting Training Loop...\")\n",
    "for epoch in range(num_epochs):\n",
    "    for i, batch in enumerate(tqdm(dataloader, desc=f'Epoch {epoch+1}/{num_epochs}')):\n",
    "        # Set model input\n",
    "        real_A = batch['A'].to(device)\n",
    "        real_B = batch['B'].to(device)\n",
    "        \n",
    "        ###### Generators A2B and B2A ######\n",
    "        optimizer_G.zero_grad()\n",
    "        \n",
    "        # Identity loss\n",
    "        # G_A2B(B) should be equal to B if real B is fed\n",
    "        same_B = netG_A2B(real_B)\n",
    "        loss_identity_B = criterion_identity(same_B, real_B) * lambda_identity\n",
    "        # G_B2A(A) should be equal to A if real A is fed\n",
    "        same_A = netG_B2A(real_A)\n",
    "        loss_identity_A = criterion_identity(same_A, real_A) * lambda_identity\n",
    "        \n",
    "        # GAN loss\n",
    "        fake_B = netG_A2B(real_A)\n",
    "        pred_fake_B = netD_B(fake_B)\n",
    "        valid = torch.ones_like(pred_fake_B, device=device)\n",
    "        loss_GAN_A2B = criterion_GAN(pred_fake_B, valid)\n",
    "        \n",
    "        fake_A = netG_B2A(real_B)\n",
    "        pred_fake_A = netD_A(fake_A)\n",
    "        loss_GAN_B2A = criterion_GAN(pred_fake_A, valid)\n",
    "        \n",
    "        # Cycle consistency loss\n",
    "        recovered_A = netG_B2A(fake_B)\n",
    "        loss_cycle_ABA = criterion_cycle(recovered_A, real_A) * lambda_cycle\n",
    "        \n",
    "        recovered_B = netG_A2B(fake_A)\n",
    "        loss_cycle_BAB = criterion_cycle(recovered_B, real_B) * lambda_cycle\n",
    "        \n",
    "        # Total generators loss\n",
    "        loss_G = loss_GAN_A2B + loss_GAN_B2A + loss_cycle_ABA + loss_cycle_BAB + loss_identity_A + loss_identity_B\n",
    "        loss_G.backward()\n",
    "        optimizer_G.step()\n",
    "        \n",
    "        ###### Discriminator A ######\n",
    "        optimizer_D_A.zero_grad()\n",
    "        \n",
    "        # Real loss\n",
    "        pred_real = netD_A(real_A)\n",
    "        valid = torch.ones_like(pred_real, device=device)\n",
    "        loss_D_real = criterion_GAN(pred_real, valid)\n",
    "        \n",
    "        # Fake loss\n",
    "        fake_A_detached = fake_A.detach()\n",
    "        pred_fake = netD_A(fake_A_detached)\n",
    "        fake = torch.zeros_like(pred_fake, device=device)\n",
    "        loss_D_fake = criterion_GAN(pred_fake, fake)\n",
    "        \n",
    "        # Total loss\n",
    "        loss_D_A_total = (loss_D_real + loss_D_fake) * 0.5\n",
    "        loss_D_A_total.backward()\n",
    "        optimizer_D_A.step()\n",
    "        \n",
    "        ###### Discriminator B ######\n",
    "        optimizer_D_B.zero_grad()\n",
    "        \n",
    "        # Real loss\n",
    "        pred_real = netD_B(real_B)\n",
    "        valid = torch.ones_like(pred_real, device=device)\n",
    "        loss_D_real = criterion_GAN(pred_real, valid)\n",
    "        \n",
    "        # Fake loss\n",
    "        fake_B_detached = fake_B.detach()\n",
    "        pred_fake = netD_B(fake_B_detached)\n",
    "        fake = torch.zeros_like(pred_fake, device=device)\n",
    "        loss_D_fake = criterion_GAN(pred_fake, fake)\n",
    "        \n",
    "        # Total loss\n",
    "        loss_D_B_total = (loss_D_real + loss_D_fake) * 0.5\n",
    "        loss_D_B_total.backward()\n",
    "        optimizer_D_B.step()\n",
    "        \n",
    "        ###### Logging ######\n",
    "        G_losses.append(loss_G.item())\n",
    "        D_A_losses.append(loss_D_A_total.item())\n",
    "        D_B_losses.append(loss_D_B_total.item())\n",
    "        cycle_losses.append((loss_cycle_ABA + loss_cycle_BAB).item())\n",
    "        identity_losses.append((loss_identity_A + loss_identity_B).item())\n",
    "        \n",
    "        ###### Print Progress ######\n",
    "        if (i+1) % 100 == 0:\n",
    "            print(f\"Epoch [{epoch+1}/{num_epochs}] Batch [{i+1}/{total_steps}] \"\n",
    "                  f\"Loss_G: {loss_G.item():.4f} Loss_D_A: {loss_D_A_total.item():.4f} \"\n",
    "                  f\"Loss_D_B: {loss_D_B_total.item():.4f}\")\n",
    "    \n",
    "    ###### Update Learning Rates ######\n",
    "    scheduler_G.step()\n",
    "    scheduler_D_A.step()\n",
    "    scheduler_D_B.step()\n",
    "    \n",
    "    ###### Save Sample Images ######\n",
    "    if (epoch+1) % 10 == 0:\n",
    "        save_sample_images(epoch, generator, dataloader, device)\n",
    "    \n",
    "    ###### Save Models ######\n",
    "    if (epoch+1) % 50 == 0:\n",
    "        os.makedirs('saved_models', exist_ok=True)\n",
    "        torch.save(netG_A2B.state_dict(), f'saved_models/netG_A2B_epoch_{epoch+1}.pth')\n",
    "        torch.save(netG_B2A.state_dict(), f'saved_models/netG_B2A_epoch_{epoch+1}.pth')\n",
    "        torch.save(netD_A.state_dict(), f'saved_models/netD_A_epoch_{epoch+1}.pth')\n",
    "        torch.save(netD_B.state_dict(), f'saved_models/netD_B_epoch_{epoch+1}.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd90cd8c-346d-4cbd-ad7a-3731b49addd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.title(\"Generator and Discriminator Loss During Training\")\n",
    "plt.plot(G_losses, label=\"G\")\n",
    "plt.plot(D_A_losses, label=\"D_A\")\n",
    "plt.plot(D_B_losses, label=\"D_B\")\n",
    "plt.xlabel(\"Iterations\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c509a4d-9bc7-4284-87d7-fe3b59632515",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_generated_images(epoch, output_dir='output'):\n",
    "    img_path = os.path.join(output_dir, f'epoch_{epoch+1}.png')\n",
    "    if os.path.exists(img_path):\n",
    "        img = Image.open(img_path)\n",
    "        plt.figure(figsize=(12,12))\n",
    "        plt.imshow(img)\n",
    "        plt.axis('off')\n",
    "        plt.title(f'Generated Images at Epoch {epoch+1}')\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(f\"No image found at {img_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
